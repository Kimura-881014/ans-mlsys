{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# とりあえず精度0.6をぎり超えるmodelを共有します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, kernel_size=5) # 畳み込み層(入力ch,フィルタ,そのサイズ)\n",
    "        self.pool = nn.MaxPool2d(2, 2) # プーリング層(領域サイズ,ストライド)\n",
    "        self.conv2 = nn.Conv2d(6, 16, kernel_size=5) # 2つめの畳み込み層\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 256) # 全結合層\n",
    "        self.dropout = nn.Dropout(p=0.5) # ドロップアウト(ドロップアウト率)\n",
    "        self.fc2 = nn.Linear(256, 256)\n",
    "        self.fc3 = nn.Linear(256, 10)\n",
    "        self.bn1 = nn.BatchNorm2d(6)\n",
    "        self.bn2 = nn.BatchNorm1d(256)\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.bn1(self.conv1(x))))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.bn2(self.fc2(x)))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "model = DNN().to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 修正箇所1 -->  train_dataloaderはimage と labelをセットで返すため、二つを受け取るようにする。\n",
    "- 修正箇所2 --> modelの入力データの形に合わせる(ここでは列数にfc1の入力28*28を指定)\n",
    "- 修正箇所3 --> loss_sum は GPUで計算した値であり、GPU上のメモリに存在する。また勾配情報はここでは必要ではないため.item()とする。\n",
    "- 修正箇所4, 修正箇所5 --> 修正箇所1と同様の理由によりリストとして受け取り、imageとlabelの二つを分ける。\n",
    "- 修正箇所6 --> 修正箇所2 と同様"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
